{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c1cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from pandas import ExcelWriter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, RNN, GRU\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Bidirectional\n",
    "from keras.layers import Input, Flatten, Activation, Reshape, RepeatVector, Concatenate, Average\n",
    "from keras.layers import Flatten, Convolution1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation, GlobalAveragePooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, MaxPooling2D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a5f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, look_back, forecast_horizon):\n",
    " X, y = list(), list()\n",
    " for i in range(len(sequence)): \n",
    "   lag_end = i + look_back\n",
    "   forecast_end = lag_end + forecast_horizon\n",
    "   if forecast_end > len(sequence):\n",
    "     break\n",
    "   seq_x, seq_y = sequence[i:lag_end], sequence[lag_end:forecast_end]\n",
    "   X.append(seq_x)\n",
    "   y.append(seq_y)\n",
    " return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0a6381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn_with_multy_head_3(frame, lags, razb):\n",
    "    for s in range(0,len(razb)-1):\n",
    "        vars()['scaler'+ '_'+str(s)]=preprocessing.MinMaxScaler() \n",
    "        vars()['frames'+ '_'+str(s)]=vars()['scaler'+ '_'+str(s)].fit_transform(frame.iloc[:,razb[s]:razb[s+1]])\n",
    "        vars()['x_train_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[0]\n",
    "        vars()['y_train_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[1]\n",
    "\n",
    "    in_layers, out_layers = list(), list()   \n",
    "    num_outputs=0\n",
    "    for s in range(0,len(razb)-1):\n",
    "        inputs = Input(shape=(vars()['x_train_all'+ '_'+str(s)].shape[1],vars()['x_train_all'+ '_'+str(s)].shape[2]))\n",
    "        conv2 = Conv1D(filters=vars()['x_train_all'+ '_'+str(s)].shape[2],\n",
    "                           kernel_size=vars()['x_train_all'+ '_'+str(s)].shape[1], activation='tanh')(inputs)\n",
    "        conv2 = Conv1D(filters=vars()['x_train_all'+ '_'+str(s)].shape[1], kernel_size=1, activation='tanh')(conv2)\n",
    "        flat = Flatten()(conv2)\n",
    "        in_layers.append(inputs)\n",
    "        out_layers.append(flat)\n",
    "        num_outputs=num_outputs+vars()['x_train_all'+ '_'+str(s)].shape[2]\n",
    "\n",
    "        # merge heads\n",
    "    merged = Concatenate(axis=1)(out_layers)\n",
    "        # interpretation\n",
    "\n",
    "    x2 = Reshape((1, merged.shape[1]))(merged)\n",
    "    x2 = Conv1D(merged.shape[1], 1, activation = 'tanh')(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "\n",
    "    outputs = Dense(num_outputs)(x2)\n",
    "    model = Model(inputs=in_layers, outputs=outputs)\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def model_cnn_with_multy_head_4(frame, lags, razb):\n",
    "    for s in range(0,len(razb)-1):\n",
    "        vars()['scaler'+ '_'+str(s)]=preprocessing.MinMaxScaler() \n",
    "        vars()['frames'+ '_'+str(s)]=vars()['scaler'+ '_'+str(s)].fit_transform(frame.iloc[:,razb[s]:razb[s+1]])\n",
    "        vars()['x_train_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[0]\n",
    "        vars()['y_train_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[1]\n",
    "\n",
    "    in_layers, out_layers = list(), list()   \n",
    "    num_outputs=0\n",
    "    for s in range(0,len(razb)-1):\n",
    "        inputs = Input(shape=(vars()['x_train_all'+ '_'+str(s)].shape[1],vars()['x_train_all'+ '_'+str(s)].shape[2]))\n",
    "        conv2 = Conv1D(filters=vars()['x_train_all'+ '_'+str(s)].shape[2],\n",
    "                           kernel_size=vars()['x_train_all'+ '_'+str(s)].shape[1], activation='tanh')(inputs)\n",
    "#         conv2 = Conv1D(filters=vars()['x_train_all'+ '_'+str(s)].shape[1], kernel_size=1, activation='tanh')(conv2)\n",
    "        flat = Flatten()(conv2)\n",
    "        in_layers.append(inputs)\n",
    "        out_layers.append(flat)\n",
    "        num_outputs=num_outputs+vars()['x_train_all'+ '_'+str(s)].shape[2]\n",
    "\n",
    "        # merge heads\n",
    "    merged = Average()(out_layers)\n",
    "    outputs = Dense(num_outputs)(merged)\n",
    "    model = Model(inputs=in_layers, outputs=outputs)\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def model_cnn_with_multy_head_5(frame, lags, razb):\n",
    "    for s in range(0,len(razb)-1):\n",
    "        vars()['scaler'+ '_'+str(s)]=preprocessing.MinMaxScaler() \n",
    "        vars()['frames'+ '_'+str(s)]=vars()['scaler'+ '_'+str(s)].fit_transform(frame.iloc[:,razb[s]:razb[s+1]])\n",
    "        vars()['x_train_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[0]\n",
    "        vars()['y_train_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[1]\n",
    "\n",
    "    in_layers, out_layers = list(), list()   \n",
    "    num_outputs=0\n",
    "    for s in range(0,len(razb)-1):\n",
    "        inputs = Input(shape=(vars()['x_train_all'+ '_'+str(s)].shape[1],vars()['x_train_all'+ '_'+str(s)].shape[2]))\n",
    "        conv2 = Conv1D(filters=vars()['x_train_all'+ '_'+str(s)].shape[2],\n",
    "                           kernel_size=vars()['x_train_all'+ '_'+str(s)].shape[1], activation='tanh')(inputs)\n",
    "#         conv2 = Conv1D(filters=vars()['x_train_all'+ '_'+str(s)].shape[1], kernel_size=1, activation='tanh')(conv2)\n",
    "        flat = Flatten()(conv2)\n",
    "        in_layers.append(inputs)\n",
    "        out_layers.append(flat)\n",
    "        num_outputs=num_outputs+vars()['x_train_all'+ '_'+str(s)].shape[2]\n",
    "\n",
    "    merged = Concatenate(axis=1)(out_layers)\n",
    "    x2 = Reshape((1, merged.shape[1]))(merged)\n",
    "    x2 = Conv1D(merged.shape[1], 1, activation = 'tanh')(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "\n",
    "    outputs = Dense(num_outputs)(x2)\n",
    "    model = Model(inputs=in_layers, outputs=outputs)\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def model_cnn_with_multy_head_6(frame, lags, razb):\n",
    "    for s in range(0,len(razb)-1):\n",
    "        vars()['scaler'+ '_'+str(s)]=preprocessing.MinMaxScaler() \n",
    "        vars()['frames'+ '_'+str(s)]=vars()['scaler'+ '_'+str(s)].fit_transform(frame.iloc[:,razb[s]:razb[s+1]])\n",
    "        vars()['x_train_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[0]\n",
    "        vars()['y_train_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[1]\n",
    "\n",
    "    in_layers, out_layers = list(), list()   \n",
    "    num_outputs=0\n",
    "    for s in range(0,len(razb)-1):\n",
    "        inputs = Input(shape=(vars()['x_train_all'+ '_'+str(s)].shape[1],vars()['x_train_all'+ '_'+str(s)].shape[2]))\n",
    "        conv2 = Conv1D(filters=vars()['x_train_all'+ '_'+str(s)].shape[2],\n",
    "                           kernel_size=vars()['x_train_all'+ '_'+str(s)].shape[1], activation='tanh')(inputs)\n",
    "#         conv2 = Conv1D(filters=vars()['x_train_all'+ '_'+str(s)].shape[1], kernel_size=1, activation='tanh')(conv2)\n",
    "        flat = Flatten()(conv2)\n",
    "        in_layers.append(inputs)\n",
    "        out_layers.append(flat)\n",
    "        num_outputs=num_outputs+vars()['x_train_all'+ '_'+str(s)].shape[2]\n",
    "\n",
    "    merged = Concatenate(axis=1)(out_layers)\n",
    "    x2 = Reshape((1, merged.shape[1]))(merged)\n",
    "    x2 = Conv1D(lags, 1, activation = 'tanh')(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "\n",
    "    outputs = Dense(num_outputs)(x2)\n",
    "    model = Model(inputs=in_layers, outputs=outputs)\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def model_cnn_with_multy_head_7(frame, lags, razb):\n",
    "    for s in range(0,len(razb)-1):\n",
    "        vars()['scaler'+ '_'+str(s)]=preprocessing.MinMaxScaler() \n",
    "        vars()['frames'+ '_'+str(s)]=vars()['scaler'+ '_'+str(s)].fit_transform(frame.iloc[:,razb[s]:razb[s+1]])\n",
    "        vars()['x_train_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[0]\n",
    "        vars()['y_train_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[1]\n",
    "\n",
    "    in_layers, out_layers = list(), list()   \n",
    "    num_outputs=0\n",
    "    for s in range(0,len(razb)-1):\n",
    "        inputs = Input(shape=(vars()['x_train_all'+ '_'+str(s)].shape[1],vars()['x_train_all'+ '_'+str(s)].shape[2]))\n",
    "        conv2 = Conv1D(filters=vars()['x_train_all'+ '_'+str(s)].shape[2],\n",
    "                           kernel_size=vars()['x_train_all'+ '_'+str(s)].shape[1], activation='tanh')(inputs)\n",
    "#         conv2 = Conv1D(filters=vars()['x_train_all'+ '_'+str(s)].shape[1], kernel_size=1, activation='tanh')(conv2)\n",
    "        flat = Flatten()(conv2)\n",
    "        in_layers.append(inputs)\n",
    "        out_layers.append(flat)\n",
    "        num_outputs=num_outputs+vars()['x_train_all'+ '_'+str(s)].shape[2]\n",
    "\n",
    "    merged = Concatenate(axis=1)(out_layers)\n",
    "    x2 = Reshape((1, merged.shape[1]))(merged)\n",
    "    x2 = LSTM(64, activation = 'tanh')(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "\n",
    "    outputs = Dense(num_outputs)(x2)\n",
    "    model = Model(inputs=in_layers, outputs=outputs)\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# Average()(xs_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bacc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model_cnn_with_multy_head_7(frame, lags, razb), show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a4d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multy_head_all(frame, lags, razb, batch_size, num_architecture):\n",
    "    for s in range(0,len(razb)-1):\n",
    "        vars()['scaler'+ '_'+str(s)]=preprocessing.MinMaxScaler() \n",
    "        vars()['frames'+ '_'+str(s)]=vars()['scaler'+ '_'+str(s)].fit_transform(frame.iloc[:,razb[s]:razb[s+1]])\n",
    "        vars()['x_train_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[0]\n",
    "        vars()['y_train_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[1]\n",
    "\n",
    "    itog_fr_x=vars()['x_train_all'+ '_'+str(0)]\n",
    "    itog_fr_y=vars()['y_train_all'+ '_'+str(0)]\n",
    "    for s in range(1,len(razb)-1):\n",
    "        itog_fr_x=[itog_fr_x,vars()['x_train_all'+ '_'+str(s)]]\n",
    "        itog_fr_y=[itog_fr_y,vars()['y_train_all'+ '_'+str(s)]]\n",
    "\n",
    "    if num_architecture==0:\n",
    "        model = model_cnn_with_multy_head_0(frame, lags, razb)\n",
    "    if num_architecture==1:\n",
    "        model = model_cnn_with_multy_head_1(frame, lags, razb)\n",
    "    if num_architecture==2:\n",
    "        model = model_cnn_with_multy_head_2(frame, lags, razb)\n",
    "    if num_architecture==3:\n",
    "        model = model_cnn_with_multy_head_3(frame, lags, razb)\n",
    "    if num_architecture==4:\n",
    "        model = model_cnn_with_multy_head_4(frame, lags, razb)\n",
    "    if num_architecture==5:\n",
    "        model = model_cnn_with_multy_head_5(frame, lags, razb)\n",
    "    if num_architecture==6:\n",
    "        model = model_cnn_with_multy_head_6(frame, lags, razb)\n",
    "    if num_architecture==7:\n",
    "        model = model_cnn_with_multy_head_7(frame, lags, razb)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "\n",
    "\n",
    "\n",
    "    model.fit(itog_fr_x,itog_fr_y, \n",
    "                                    epochs=50, \n",
    "                                    batch_size=batch_size, #от размера батчей зависит точность модели, очень странная хуйня\n",
    "                                    verbose=0,\n",
    "                                    callbacks=[early_stop],\n",
    "                                    validation_split=0\n",
    "    #                                 shuffle=False,\n",
    "                                    )   \n",
    "    return model\n",
    "\n",
    "def sm_wind_multy_head(frame,lags,razb,batch_size, num_architecture):\n",
    "    prog_frame=pd.DataFrame(columns=frame.columns)\n",
    "    orig_frame=pd.DataFrame(columns=frame.columns)\n",
    "    iteratation_5=int((len(frame)-399)/5)+1\n",
    "#     iteratation_5=50\n",
    "    for i in range(0,iteratation_5):\n",
    "        model=multy_head_all(frame.iloc[0+5*i:399+5*i,:], lags,razb,batch_size, num_architecture)\n",
    "        frames=frame.iloc[0+5*i:399+1+5*i,:]\n",
    "\n",
    "        s=0\n",
    "        vars()['scaler'+ '_'+str(s)]=preprocessing.MinMaxScaler() \n",
    "        vars()['frames'+ '_'+str(s)]=vars()['scaler'+ '_'+str(s)].fit_transform(frames.iloc[:,razb[s]:razb[s+1]])\n",
    "        vars()['x_test_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[0]\n",
    "        vars()['y_test_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[1]\n",
    "        vars()['x_input'+ '_'+str(s)]=vars()['x_test_all'+ '_'+str(s)][-1]\n",
    "        vars()['x_input'+ '_'+str(s)]=vars()['x_input'+ '_'+str(s)].reshape((1,\n",
    "                                                                                 vars()['x_test_all'+ '_'+str(s)].shape[1],\n",
    "                                                                                 vars()['x_test_all'+ '_'+str(s)].shape[2]))\n",
    "        x_input=vars()['x_input'+ '_'+str(s)]\n",
    "\n",
    "\n",
    "        for s in range(1,len(frame.columns)):\n",
    "        #     print(s)\n",
    "            vars()['scaler'+ '_'+str(s)]=preprocessing.MinMaxScaler() \n",
    "            vars()['frames'+ '_'+str(s)]=vars()['scaler'+ '_'+str(s)].fit_transform(frames.iloc[:,razb[s]:razb[s+1]])\n",
    "            vars()['x_test_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[0]\n",
    "            vars()['y_test_all'+ '_'+str(s)]=split_sequence(vars()['frames'+ '_'+str(s)],lags,1)[1]\n",
    "\n",
    "            vars()['x_input'+ '_'+str(s)]=vars()['x_test_all'+ '_'+str(s)][-1]\n",
    "            vars()['x_input'+ '_'+str(s)]=vars()['x_input'+ '_'+str(s)].reshape((1,\n",
    "                                                                                 vars()['x_test_all'+ '_'+str(s)].shape[1],\n",
    "                                                                                 vars()['x_test_all'+ '_'+str(s)].shape[2]))\n",
    "\n",
    "            x_input=[x_input,vars()['x_input'+ '_'+str(s)]]\n",
    "\n",
    "\n",
    "        # i=0\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        s=0\n",
    "        prog_all=[]\n",
    "        orig_all=[]\n",
    "        vars()['testPredict'+ '_'+str(s)] = vars()['scaler'+ '_'+str(s)].inverse_transform(yhat[0:1,s:(s+1)])[0] \n",
    "        vars()['testY'+ '_'+str(s)]=vars()['scaler'+ '_'+str(s)].inverse_transform(vars()['y_test_all'+ '_'+str(s)][-1])\n",
    "        prog_all.append(vars()['testPredict'+ '_'+str(s)])\n",
    "        orig_all.append(vars()['testY'+ '_'+str(s)][0])\n",
    "        for s in range(1,len(frame.columns)):\n",
    "            vars()['testPredict'+ '_'+str(s)] = vars()['scaler'+ '_'+str(s)].inverse_transform(yhat[0:1,s:(s+1)])[0] \n",
    "            vars()['testY'+ '_'+str(s)]=vars()['scaler'+ '_'+str(s)].inverse_transform(vars()['y_test_all'+ '_'+str(s)][-1])\n",
    "            prog_all.append(vars()['testPredict'+ '_'+str(s)])\n",
    "            orig_all.append(vars()['testY'+ '_'+str(s)][0])\n",
    "        prog_frame.loc[i]=prog_all\n",
    "        orig_frame.loc[i]=orig_all\n",
    "    return prog_frame, orig_frame\n",
    "\n",
    "def povtor_multy_head(frame,lags,razb,batch_size, num_architecture, povtor):\n",
    "    for i in range(0,len(frame.columns)):\n",
    "        vars()['frrr'+ '_'+str(i)]=pd.DataFrame()\n",
    "\n",
    "    for p in range(0,povtor):\n",
    "        cc=sm_wind_multy_head(frame,lags,razb,batch_size, num_architecture)\n",
    "        for s in range(len(cc[0].columns)):\n",
    "\n",
    "            zz=[]\n",
    "            for i in range(0,len(cc[0].iloc[:,s])):\n",
    "                zz.append(cc[0].iloc[i,s][0])\n",
    "            vars()['frrr'+ '_'+str(s)][str(p)]=np.exp(zz)\n",
    "\n",
    "    pogr=[]\n",
    "\n",
    "    s=0\n",
    "    vars()['orig'+ '_'+str(s)]=[]        \n",
    "    for i in range(0,len(cc[1].iloc[:,s])):\n",
    "        vars()['orig'+ '_'+str(s)].append(cc[1].iloc[i,s][0])\n",
    "    vars()['orig'+ '_'+str(s)]=np.exp(vars()['orig'+ '_'+str(s)])\n",
    "    vars()['prog_mean'+ '_'+str(s)]=vars()['frrr'+ '_'+str(s)].transpose().mean()\n",
    "    pogr.append((100*abs(vars()['orig'+ '_'+str(s)]-vars()['prog_mean'+ '_'+str(s)])/vars()['orig'+ '_'+str(s)]).mean())\n",
    "    all_orig=vars()['orig'+ '_'+str(s)]\n",
    "    all_prog_mean=vars()['prog_mean'+ '_'+str(s)]\n",
    "\n",
    "    for s in range(1,len(cc[0].columns)): \n",
    "\n",
    "        vars()['orig'+ '_'+str(s)]=[]        \n",
    "        for i in range(0,len(cc[1].iloc[:,s])):\n",
    "            vars()['orig'+ '_'+str(s)].append(cc[1].iloc[i,s][0])\n",
    "        vars()['orig'+ '_'+str(s)]=np.exp(vars()['orig'+ '_'+str(s)])\n",
    "        vars()['prog_mean'+ '_'+str(s)]=vars()['frrr'+ '_'+str(s)].transpose().mean()\n",
    "        pogr.append((100*abs(vars()['orig'+ '_'+str(s)]-vars()['prog_mean'+ '_'+str(s)])/vars()['orig'+ '_'+str(s)]).mean())\n",
    "        all_orig=[all_orig,vars()['orig'+ '_'+str(s)]]\n",
    "        all_prog_mean=[all_prog_mean,vars()['prog_mean'+ '_'+str(s)]]\n",
    "    \n",
    "    return pogr, all_orig, all_prog_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b925289",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"C:/Users/VIP13/Статья 2/Котировки 6\")\n",
    "frame_3=pd.read_csv('all_snp_btc_rv_rr.csv', delimiter=';')\n",
    "frame=frame_3.iloc[:,1:].copy() #на входе подаются квадраты волатильностей, поэтому сначала из них берем корни, а потом логарифмируем\n",
    "frame=frame.loc[:, [c for c in frame.columns if (frame[c]>0).all()]]\n",
    "frame=np.log(np.sqrt(frame))\n",
    "ind=[i for i in range(0,len(frame))]\n",
    "frame.index=ind\n",
    "razb=[0,1,3]\n",
    "lags=5\n",
    "\n",
    "cc0=povtor_multy_head(frame,5,razb,5, 4, 10)\n",
    "print(cc0[0])\n",
    "cc1=povtor_multy_head(frame,5,razb,5, 5, 10)\n",
    "print(cc1[0])\n",
    "cc2=povtor_multy_head(frame,5,razb,5, 6, 10)\n",
    "print(cc2[0])\n",
    "cc3=povtor_multy_head(frame,5,razb,5, 7, 10)\n",
    "print(cc3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb82cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
