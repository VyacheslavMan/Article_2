{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835093ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from pandas import ExcelWriter\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "from keras import regularizers\n",
    "\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"C:/Users/VIP13/Статья 2/Котировки 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fad773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate dataset into train/test sets\n",
    "# forecast monthly births with xgboost\n",
    " \n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX,eta, gamma, max_depth):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = XGBRegressor(objective='reg:squarederror', n_estimators=100, eta=eta, gamma=gamma, max_depth=max_depth)\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, eta, gamma, max_depth):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX, eta=eta, gamma=gamma, max_depth=max_depth)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "# \t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    "\n",
    "def progon(frame, n_in, n_test, eta, gamma, max_depth):\n",
    "    iteratation_5=int((len(frame)-399)/5)+1\n",
    "    y=[]\n",
    "    yhat=[]\n",
    "\n",
    "    for i in range(0,iteratation_5):\n",
    "        series=DataFrame(np.log(np.sqrt(frame.iloc[0+5*i:399+5*i+1])))\n",
    "        values = series.values\n",
    "        # transform the time series data into supervised learning\n",
    "        data = series_to_supervised(values, n_in=5)\n",
    "        # evaluate\n",
    "        progn=walk_forward_validation(data, n_test=1, eta=eta, gamma=gamma, max_depth=max_depth)\n",
    "\n",
    "        y.append(progn[1])\n",
    "        yhat.append(progn[2])\n",
    "    c=np.exp(y)\n",
    "    cc=np.exp(yhat)\n",
    "    mape=(100*abs(c-cc)/c).mean()\n",
    "    \n",
    "    \n",
    "    frame_pr=pd.DataFrame(c)\n",
    "    frame_pr['prog']=cc\n",
    "    fr=frame_pr.iloc[1:,0:].copy()\n",
    "    ind=[i for i in range(0,len(frame_pr)-1)]\n",
    "    fr.index=ind\n",
    "    frr=frame_pr.iloc[:-1,0:].copy()\n",
    "    frr.index=ind\n",
    "\n",
    "    frame_diff=fr-frr\n",
    "    frame_diff[frame_diff < 0] = 0\n",
    "    frame_diff[frame_diff > 0] = 1\n",
    "    f1=[]\n",
    "    f1.append(0)\n",
    "    accuracy=[]\n",
    "    for i in range(1,len(frame_diff.columns)):\n",
    "        accuracy.append(accuracy_score(frame_diff.iloc[:,0], frame_diff.iloc[:,i]))\n",
    "\n",
    "    return c, cc, mape, accuracy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e513e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "for eta in np.arange(0.1,1,0.1):\n",
    "    for gamma in np.arange(0.1,1,0.1):\n",
    "        for max_depth in np.arange(1,11,1):\n",
    "#             for reg_lambda in np.arange(0,1,0.1):\n",
    "#                 for reg_alpha in np.arange(0,1,0.1):\n",
    "#                     for subsample in np.arange(0,1,0.1):\n",
    "#                         for colsample_bytree in np.arange(0,1,0.1):\n",
    "            name='boost'+'_'+str(eta)+'_'+str(gamma)+'_'+str(max_depth)\n",
    "            names.append(name)\n",
    "\n",
    "all_frame=pd.DataFrame(columns=names)                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcbf1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=pd.read_csv('all_snp_btc_rv_rr.csv', delimiter=';',decimal='.')\n",
    "\n",
    "fraa=pd.DataFrame()\n",
    "\n",
    "fraa['y']=frame['rv_shk_snp']\n",
    "# fraa['y']=frame['rv_shk_btc']\n",
    "\n",
    "ll=0\n",
    "mapes=[]\n",
    "accuracys=[]\n",
    "for eta in np.arange(0.1,1,0.1):\n",
    "    for gamma in np.arange(0.1,1,0.1):\n",
    "        for max_depth in np.arange(1,11,1):\n",
    "            ll=ll+1\n",
    "            name='boost'+'_'+str(eta)+'_'+str(gamma)+'_'+str(max_depth)\n",
    "            prog=progon(fraa, 5, 1, eta, gamma, max_depth)\n",
    "            \n",
    "            pr=[]\n",
    "            for i in prog[1]:\n",
    "                pr.append(i)\n",
    "\n",
    "            all_frame[name]=pr\n",
    "#             all_frame[name]=np.array(prog[1])\n",
    "            mapes.append(prog[2])\n",
    "            accuracys.append(prog[3])\n",
    "            print(ll)\n",
    "            \n",
    "            \n",
    "pr=[]\n",
    "for i in prog[0]:\n",
    "    pr.append(i)\n",
    "all_frame['orig_data']=pr\n",
    "all_frame.to_csv('all_frame_snp_boosting.csv')\n",
    "# all_frame.to_csv('all_frame_btc_boosting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=pd.read_csv('all_frame_snp_boosting.csv', delimiter=',',decimal='.')\n",
    "# frame=pd.read_csv('all_frame_btc_boosting.csv', delimiter=',',decimal='.')\n",
    "orig=frame['orig_data']\n",
    "\n",
    "# frame.insert(0, \"exp_prog\", np.array(frame1['exp_prog']))\n",
    "# frame['exp_prog']=frame1['exp_prog']\n",
    "origg=[]\n",
    "pri=[]\n",
    "for i in orig:\n",
    "    origg.append(float(i[1:-1]))\n",
    "frae=pd.DataFrame(origg)\n",
    "\n",
    "for i in range(1, len(frame.columns)-1):\n",
    "    prognoz=frame[frame.columns[i]]\n",
    "    pri=[]\n",
    "    for j in prognoz:\n",
    "        pri.append(float(j[1:-1]))\n",
    "    frae[frame.columns[i]]=pri  \n",
    "        \n",
    "mape=[]\n",
    "mape.append(0)\n",
    "c=frae[frae.columns[0]]\n",
    "for i in range(1,len(frae.columns)):\n",
    "    cc=frae[frae.columns[i]]\n",
    "    mape.append((100*abs(c-cc)/c).mean())\n",
    "# print(mape)\n",
    "fraes=frae.transpose()\n",
    "fraes['mape']=mape\n",
    "frae_sort=fraes.sort_values(by='mape')\n",
    "frae_sort=frae_sort.transpose()\n",
    "# print(frae_sort)\n",
    "print(frae_sort.iloc[-1,1:6])\n",
    "frame_pr=pd.DataFrame(frae[frae.columns[0]])\n",
    "accuracy=[]\n",
    "accuracy.append(0)\n",
    "for i in range(1,len(frae.columns)):\n",
    "    frame_pr['prog']=frae[frae.columns[i]]\n",
    "    fr=frame_pr.iloc[1:,0:].copy()\n",
    "    ind=[i for i in range(0,len(frame_pr)-1)]\n",
    "    fr.index=ind\n",
    "    frr=frame_pr.iloc[:-1,0:].copy()\n",
    "    frr.index=ind\n",
    "    frame_diff=fr-frr\n",
    "    frame_diff[frame_diff < 0] = 0\n",
    "    frame_diff[frame_diff > 0] = 1\n",
    "\n",
    "    for j in range(1,len(frame_diff.columns)):\n",
    "        accuracy.append(accuracy_score(frame_diff.iloc[:,0], frame_diff.iloc[:,j]))\n",
    "# print(accuracy)\n",
    "fraes['accuracy']=accuracy\n",
    "\n",
    "frae_sort_1=fraes.sort_values(by='accuracy', ascending=False)\n",
    "frae_sort_1=frae_sort_1.transpose()\n",
    "print(frae_sort_1.iloc[-1,0:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
