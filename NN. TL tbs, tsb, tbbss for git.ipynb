{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from pandas import ExcelWriter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, RNN, GRU\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Bidirectional\n",
    "from keras.layers import Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from keras.layers import Flatten, Convolution1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation, GlobalAveragePooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, MaxPooling2D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import os\n",
    "from keras import regularizers\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "os.chdir(\"C:/Users/VIP13/Статья 2/Котировки 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e3519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, look_back, forecast_horizon):\n",
    " X, y = list(), list()\n",
    " for i in range(len(sequence)): \n",
    "   lag_end = i + look_back\n",
    "   forecast_end = lag_end + forecast_horizon\n",
    "   if forecast_end > len(sequence):\n",
    "     break\n",
    "   seq_x, seq_y = sequence[i:lag_end], sequence[lag_end:forecast_end]\n",
    "   X.append(seq_x)\n",
    "   y.append(seq_y)\n",
    " return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec845cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def architecture_one_head_0(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1]\n",
    "                      , activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])\n",
    "                     ,name='one_layer_CNN'))\n",
    "#     modelC.add(Conv1D(x_train.shape[2], kernel_size=1, activation='tanh'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='one_layer_CNN_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_1(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_2'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_2(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_2'))\n",
    "    modelC.add(Conv1D(2*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_3(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_2'))\n",
    "    modelC.add(Conv1D(2*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3'))\n",
    "    modelC.add(Conv1D(1*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_4'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_4(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_5(x_train):\n",
    "   \n",
    "    modelC = Sequential()\n",
    "    modelC.add(Dense(64,activation='tanh',\n",
    "                     name='MLP_1',\n",
    "                     input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    for i in range(0,10):\n",
    "        modelC.add(Dense(32, name=str('MLP_'+str(i+2))))\n",
    "    modelC.add(Dense(x_train.shape[2], activation='tanh', name='MLP_output'))\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_6(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(LSTM(5*x_train.shape[1], return_sequences=True\n",
    "                    ,name='two_layer_LSTM_1'\n",
    "                    , activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(LSTM(10, activation='tanh'\n",
    "                    ,name='two_layer_LSTM_2'\n",
    "                    , return_sequences=True))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layers_LSTM_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_7(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(LSTM(5*x_train.shape[1], return_sequences=True\n",
    "                    ,name='one_layer_LSTM_1'\n",
    "                    , activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "#     modelC.add(LSTM(25, activation='tanh', return_sequences=True))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='one_layer_LSTM_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_8(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_2',bias_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.01)))\n",
    "    modelC.add(Dropout(0.1))\n",
    "    modelC.add(Conv1D(2*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3'))\n",
    "    modelC.add(Conv1D(1*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_4'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_9(x_train):\n",
    "    model_close = Sequential()\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "\n",
    "    L1 = LSTM(16, activation='tanh', return_sequences=True, kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
    "    L2 = LSTM(4, activation='tanh', return_sequences=False)(L1)\n",
    "    L3 = RepeatVector(x_train.shape[1])(L2)\n",
    "    L4 = LSTM(4, activation='tanh', return_sequences=True)(L3)\n",
    "    L5 = LSTM(16, activation='tanh', return_sequences=True)(L4)\n",
    "\n",
    "    outputs = TimeDistributed(Dense(x_train.shape[2]))(L5)\n",
    "\n",
    "    model_close = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    model_close.compile(loss='mae', optimizer='adam')\n",
    "    return model_close\n",
    "\n",
    "def architecture_one_head_10(x_train):\n",
    "    model_close = Sequential()\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "\n",
    "    L1 = LSTM(16, activation='tanh', return_sequences=True, kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
    "    L2 = LSTM(4, activation='tanh', return_sequences=False)(L1)\n",
    "    L3 = RepeatVector(x_train.shape[1])(L2)\n",
    "    L4 = LSTM(4, activation='tanh', return_sequences=True)(L3)\n",
    "    L5 = LSTM(16, activation='tanh', return_sequences=True)(L4)\n",
    "\n",
    "    outputs = TimeDistributed(Dense(x_train.shape[2]))(L5)\n",
    "\n",
    "    model_close = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    model_close.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n",
    "    return model_close\n",
    "\n",
    "def architecture_one_head_11(x_train):\n",
    "\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(1*x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh',padding='same', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(Conv1D(2*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_2',padding='same'))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3',padding='same'))\n",
    "    modelC.add(Conv1D(4*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3',padding='same'))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3',padding='same'))\n",
    "    modelC.add(Conv1D(2*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3',padding='same'))\n",
    "    modelC.add(Conv1D(1*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3',padding='same'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62abdc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_head(data, lags, batch_size, num_architecture):\n",
    "        scaler = preprocessing.MinMaxScaler() \n",
    "        frame= scaler.fit_transform(data)\n",
    "        x_train=split_sequence(frame,lags,1)[0]\n",
    "        y_train=split_sequence(frame,lags,1)[1]\n",
    "        \n",
    "        if num_architecture==0:\n",
    "            model=architecture_one_head_0(x_train)\n",
    "        if num_architecture==1:\n",
    "            model=architecture_one_head_1(x_train)\n",
    "        if num_architecture==2:\n",
    "            model=architecture_one_head_2(x_train)\n",
    "        if num_architecture==3:\n",
    "            model=architecture_one_head_3(x_train)\n",
    "        if num_architecture==4:\n",
    "            model=architecture_one_head_4(x_train)\n",
    "        if num_architecture==5:\n",
    "            model=architecture_one_head_5(x_train)\n",
    "        if num_architecture==6:\n",
    "            model=architecture_one_head_6(x_train)\n",
    "        if num_architecture==7:\n",
    "            model=architecture_one_head_7(x_train)\n",
    "        if num_architecture==8:\n",
    "            model=architecture_one_head_8(x_train)\n",
    "        if num_architecture==9:\n",
    "            model=architecture_one_head_9(x_train)\n",
    "        if num_architecture==10:\n",
    "            model=architecture_one_head_10(x_train)\n",
    "        if num_architecture==11:\n",
    "            model=architecture_one_head_11(x_train)\n",
    "\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "        model.fit(x_train,\n",
    "                  y_train, \n",
    "                    epochs=200, \n",
    "                                    batch_size=batch_size, #от размера батчей зависит точность модели, очень странная хуйня\n",
    "                                    verbose=0,\n",
    "                                    callbacks=[early_stop],\n",
    "                                    validation_split=0\n",
    "                                    )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89addfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_3=pd.read_csv('all_snp_btc_rv_rr.csv', delimiter=';')\n",
    "frame=frame_3.iloc[:,1:].copy() #на входе подаются квадраты волатильностей, поэтому сначала из них берем корни, а потом логарифмируем\n",
    "frame=frame.loc[:, [c for c in frame.columns if (frame[c]>0).all()]]\n",
    "frame=np.log(np.sqrt(frame))\n",
    "ind=[i for i in range(0,len(frame))]\n",
    "frame.index=ind\n",
    "\n",
    "frame_learns=pd.DataFrame()\n",
    "frame_learns['rv_shk_btc']=frame['rv_shk_btc']\n",
    "\n",
    "\n",
    "frame_transfs=pd.DataFrame()\n",
    "frame_transfs['rv_shk_snp']=frame['rv_shk_snp']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba51c1e",
   "metadata": {},
   "source": [
    "# TBS/TSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21051e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prog_sm_wind_one_head(frame_learn, frame_transf, lags, batch_size, num_architecture):\n",
    "\n",
    "    iteratation_5=int((len(frame_learn)-399)/5)+1\n",
    "#     iteratation_5=5\n",
    "    \n",
    "    prog=pd.DataFrame(columns=frame_transf.columns)\n",
    "    orig=pd.DataFrame(columns=frame_transf.columns)\n",
    "#     frr.loc[0]=testPredict\n",
    "    for i in range(0,iteratation_5):\n",
    "        modelC=one_head(frame_learn.iloc[0+5*i:399+5*i,:], lags, batch_size, num_architecture)\n",
    "        scaler = preprocessing.MinMaxScaler() \n",
    "        frames=scaler.fit_transform(frame_transf.iloc[0+5*i:399+1+5*i,:])\n",
    "        x_test=split_sequence(frames,lags,1)[0]\n",
    "        y_test=split_sequence(frames,lags,1)[1]\n",
    "        x_input = x_test[-1]\n",
    "        x_input = x_input.reshape((1, x_test.shape[1], x_test.shape[2]))\n",
    "        yhat = modelC.predict(x_input, verbose=0)\n",
    "        testPredict = scaler.inverse_transform(yhat[0])\n",
    "        testPredict=testPredict[0]\n",
    "        testY = scaler.inverse_transform(y_test[-1])\n",
    "        \n",
    "        prog.loc[i]=testPredict\n",
    "        orig.loc[i]=testY[0]\n",
    "    return orig, prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a194b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def povtor_prog_sqrt(frame_learn, frame_transf, lags, batch_size, num_architecture, povtor):\n",
    "\n",
    "    prog_f1=pd.DataFrame()\n",
    "    for i in range(0,povtor):\n",
    "        prog=prog_sm_wind_one_head(frame_learn, frame_transf, lags, batch_size, num_architecture)\n",
    "        prog_f1[str(i)]=prog[-1]\n",
    "    f1_mape=pd.DataFrame()\n",
    "    f1_mape['mean']=prog_f1.transpose().mean()\n",
    "    f1_mape['exp_prog']=np.exp(prog_f1).transpose().mean()\n",
    "    f1_mape['orig']=prog[-2]\n",
    "    f1_mape['orig_exp']=np.exp(prog[-2])\n",
    "    \n",
    "    c=np.exp(prog_f1).transpose().mean()\n",
    "    cc=f1_mape['orig_exp']\n",
    "    mape=100*(abs(c-cc)/cc).mean()\n",
    "    return f1_mape, mape, prog_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e3eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tbs\n",
    "prog01snp=povtor_prog_sqrt(frame_learns, frame_transfs, 5, 5,0,10)\n",
    "print(prog01snp[1])\n",
    "prog04snp=povtor_prog_sqrt(frame_learns, frame_transfs, 5, 5,4,10)\n",
    "print(prog04snp[1])\n",
    "#tsb\n",
    "prog01btc=povtor_prog_sqrt(frame_transfs, frame_learns, 5, 5,0,10)\n",
    "print(prog01btc[1])\n",
    "prog04btc=povtor_prog_sqrt(frame_transfs, frame_learns, 5, 5,4,10)\n",
    "print(prog04btc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937d94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_prog=pd.DataFrame()\n",
    "btc_prog['orig_exp']=prog01btc[0]['orig_exp']\n",
    "btc_prog['prog_0']=prog01btc[0]['exp_prog']\n",
    "btc_prog['prog_4']=prog04btc[0]['exp_prog']\n",
    "\n",
    "snp_prog=pd.DataFrame()\n",
    "snp_prog['orig_exp']=prog01snp[0]['orig_exp']\n",
    "snp_prog['prog_0']=prog01snp[0]['exp_prog']\n",
    "snp_prog['prog_4']=prog04snp[0]['exp_prog']\n",
    "\n",
    "\n",
    "btc_prog.to_csv('btc_prog_transf.csv')\n",
    "\n",
    "snp_prog.to_csv('snp_prog_transf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e747d7ae",
   "metadata": {},
   "source": [
    "# tbbss/tssbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, hstack, vstack\n",
    "def one_head(frame_learn,frame_transf, lags, batch_size, num_architecture):\n",
    "    scaler = preprocessing.MinMaxScaler() \n",
    "    frame= scaler.fit_transform(frame_learn)\n",
    "    x_train=split_sequence(frame,lags,1)[0]\n",
    "    y_train=split_sequence(frame,lags,1)[1]\n",
    "\n",
    "    for i in range(0,len(frame_transf.columns)):\n",
    "        tmp_fr=pd.DataFrame(frame_transf.iloc[:,i])\n",
    "        frame_1=scaler.fit_transform(tmp_fr)\n",
    "        x_train_1=split_sequence(frame_1,lags,1)[0]\n",
    "        y_train_1=split_sequence(frame_1,lags,1)[1]\n",
    "        x_train=vstack([x_train, x_train_1])\n",
    "        y_train=vstack([y_train, y_train_1])\n",
    "\n",
    "    if num_architecture==0:\n",
    "        model=architecture_one_head_0(x_train)\n",
    "    if num_architecture==1:\n",
    "        model=architecture_one_head_1(x_train)\n",
    "    if num_architecture==2:\n",
    "        model=architecture_one_head_2(x_train)\n",
    "    if num_architecture==3:\n",
    "        model=architecture_one_head_3(x_train)\n",
    "    if num_architecture==4:\n",
    "         model=architecture_one_head_4(x_train)\n",
    "    if num_architecture==5:\n",
    "        model=architecture_one_head_5(x_train)\n",
    "    if num_architecture==6:\n",
    "        model=architecture_one_head_6(x_train)\n",
    "    if num_architecture==7:\n",
    "        model=architecture_one_head_7(x_train)\n",
    "    if num_architecture==8:\n",
    "        model=architecture_one_head_8(x_train)\n",
    "    if num_architecture==9:\n",
    "        model=architecture_one_head_9(x_train)\n",
    "    if num_architecture==10:\n",
    "        model=architecture_one_head_10(x_train)\n",
    "    if num_architecture==11:\n",
    "        model=architecture_one_head_11(x_train)\n",
    "    if num_architecture==12:\n",
    "        model=architecture_one_head_12(x_train)\n",
    "\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    model.fit(x_train,\n",
    "                      y_train, \n",
    "                        epochs=200, \n",
    "                                        batch_size=batch_size, #от размера батчей зависит точность модели, очень странная хуйня\n",
    "                                        verbose=0,\n",
    "                                        callbacks=[early_stop],\n",
    "                                        validation_split=0\n",
    "                                        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ef9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prog_sm_wind_one_head(frame_learn,frame_transf, lags, batch_size, num_architecture\n",
    "                         ,len_wind, step_smooth):\n",
    "\n",
    "    iteratation_5=int((len(frame_learn)-len_wind)/step_smooth)+1\n",
    "#     iteratation_5=3\n",
    "    columnss=[]\n",
    "    columnss.append(frame_learn.columns[0])\n",
    "    for k in range(0,len(frame_transf.columns)):\n",
    "        columnss.append(str(frame_transf.columns[k]))\n",
    "\n",
    "    prog=pd.DataFrame(columns=columnss)\n",
    "    orig=pd.DataFrame(columns=columnss)\n",
    "\n",
    "    for i in range(0,iteratation_5):\n",
    "        modelC=one_head(frame_learn.iloc[0+step_smooth*i:len_wind+step_smooth*i,:],frame_transf.iloc[0+step_smooth*i:len_wind+step_smooth*i,:], lags, batch_size, num_architecture)\n",
    "        tmp_prog=[]\n",
    "        tmp_orig=[]\n",
    "        scaler = preprocessing.MinMaxScaler() \n",
    "        frames=scaler.fit_transform(frame_learn.iloc[0+step_smooth*i:len_wind+1+step_smooth*i,:])\n",
    "        x_test=split_sequence(frames,lags,1)[0]\n",
    "        y_test=split_sequence(frames,lags,1)[1]\n",
    "        x_input = x_test[-1]\n",
    "        x_input = x_input.reshape((1, x_test.shape[1], x_test.shape[2]))\n",
    "        yhat = modelC.predict(x_input, verbose=0)\n",
    "        testPredict = scaler.inverse_transform(yhat[0])\n",
    "        testPredict=testPredict[0]\n",
    "        testY = scaler.inverse_transform(y_test[-1])\n",
    "\n",
    "        tmp_prog.append(testPredict[0])\n",
    "        tmp_orig.append(testY[0][0])\n",
    "\n",
    "        for j in range(0,len(frame_transfs.columns)):\n",
    "            scaler = preprocessing.MinMaxScaler() \n",
    "            frames=scaler.fit_transform(frame_transf.iloc[0+step_smooth*i:len_wind+1+step_smooth*i,j:j+1])\n",
    "            x_test=split_sequence(frames,lags,1)[0]\n",
    "            y_test=split_sequence(frames,lags,1)[1]\n",
    "            x_input = x_test[-1]\n",
    "            x_input = x_input.reshape((1, x_test.shape[1], x_test.shape[2]))\n",
    "            yhat = modelC.predict(x_input, verbose=0)\n",
    "            testPredict = scaler.inverse_transform(yhat[0])\n",
    "            testPredict=testPredict[0]\n",
    "            testY = scaler.inverse_transform(y_test[-1])\n",
    "\n",
    "            tmp_prog.append(testPredict[0])\n",
    "            tmp_orig.append(testY[0][0])\n",
    "        prog.loc[i]=np.exp(tmp_prog)\n",
    "        orig.loc[i]=np.exp(tmp_orig)\n",
    "    return orig, prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff55b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def povtor_prog_sqrt(frame_learn,frame_transf, lags, batch_size, num_architecture\n",
    "                         ,len_wind, step_smooth, progon):    \n",
    "    \n",
    "    progn=prog_sm_wind_one_head(frame_learn,frame_transf, lags, batch_size, num_architecture\n",
    "                         ,len_wind, step_smooth)\n",
    "    orig=progn[0]\n",
    "    prognoz=progn[1]\n",
    "    for i in range(1,progon):\n",
    "        tmp_pr=prog_sm_wind_one_head(frame_learn,frame_transf, lags, batch_size, num_architecture\n",
    "                         ,len_wind, step_smooth)\n",
    "        prognoz=prognoz+tmp_pr[1]\n",
    "    prognoz=prognoz/progon\n",
    "    mape=(100*abs((orig-prognoz)/orig)).mean()\n",
    "    return mape, prognoz, orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_progn_4=povtor_prog_sqrt(frame_learns,frame_transfs, 5, 5, 4\n",
    "                         ,len_wind=399, step_smooth=5, progon=10)\n",
    "print(my_progn_4[0])\n",
    "my_progn_4[1].to_csv('transfer_skl_prog_4.csv')\n",
    "my_progn_4[2].to_csv('transfer_skl_orig_4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
