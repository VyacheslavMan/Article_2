{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de192b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from pandas import ExcelWriter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, RNN, GRU\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Bidirectional\n",
    "from keras.layers import Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from keras.layers import Flatten, Convolution1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation, GlobalAveragePooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, MaxPooling2D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import os\n",
    "from keras import regularizers\n",
    "from keras.layers import BatchNormalization\n",
    "from numpy.random import seed\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "os.chdir(\"C:/Users/VIP13/Статья 2/Котировки 6\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478525c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, look_back, forecast_horizon):\n",
    " X, y = list(), list()\n",
    " for i in range(len(sequence)): \n",
    "   lag_end = i + look_back\n",
    "   forecast_end = lag_end + forecast_horizon\n",
    "   if forecast_end > len(sequence):\n",
    "     break\n",
    "   seq_x, seq_y = sequence[i:lag_end], sequence[lag_end:forecast_end]\n",
    "   X.append(seq_x)\n",
    "   y.append(seq_y)\n",
    " return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e07f7a",
   "metadata": {},
   "source": [
    "# Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d527513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def architecture_one_head_0(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1]\n",
    "                      , activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])\n",
    "                     ,name='one_layer_CNN'))\n",
    "#     modelC.add(Conv1D(x_train.shape[2], kernel_size=1, activation='tanh'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='one_layer_CNN_model_output'))\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_1(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_2'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_2(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_2'))\n",
    "    modelC.add(Conv1D(2*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_3(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_2'))\n",
    "    modelC.add(Conv1D(2*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3'))\n",
    "    modelC.add(Conv1D(1*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_4'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_4(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_5(x_train):\n",
    "   \n",
    "    modelC = Sequential()\n",
    "    modelC.add(Dense(64,activation='tanh',\n",
    "                     name='MLP_1',\n",
    "                     input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    for i in range(0,10):\n",
    "        modelC.add(Dense(32, name=str('MLP_'+str(i+2))))\n",
    "    modelC.add(Dense(x_train.shape[2], activation='tanh', name='MLP_output'))\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_6(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(LSTM(5*x_train.shape[1], return_sequences=True\n",
    "                    ,name='two_layer_LSTM_1'\n",
    "                    , activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(LSTM(10, activation='tanh'\n",
    "                    ,name='two_layer_LSTM_2'\n",
    "                    , return_sequences=True))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layers_LSTM_model_output'))\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_7(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(LSTM(5*x_train.shape[1], return_sequences=True\n",
    "                    ,name='one_layer_LSTM_1'\n",
    "                    , activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "#     modelC.add(LSTM(25, activation='tanh', return_sequences=True))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='one_layer_LSTM_model_output'))\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_8(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_2',bias_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.01)))\n",
    "    modelC.add(Dropout(0.1))\n",
    "    modelC.add(Conv1D(2*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3'))\n",
    "    modelC.add(Conv1D(1*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_4'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_9(x_train):\n",
    "    model_close = Sequential()\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "\n",
    "    L1 = LSTM(16, activation='tanh', return_sequences=True, kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
    "    L2 = LSTM(4, activation='tanh', return_sequences=False)(L1)\n",
    "    L3 = RepeatVector(x_train.shape[1])(L2)\n",
    "    L4 = LSTM(4, activation='tanh', return_sequences=True)(L3)\n",
    "    L5 = LSTM(16, activation='tanh', return_sequences=True)(L4)\n",
    "\n",
    "    outputs = TimeDistributed(Dense(x_train.shape[2]))(L5)\n",
    "\n",
    "    model_close = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    model_close.compile(loss='mae', optimizer='adam')\n",
    "    return model_close\n",
    "\n",
    "def architecture_one_head_10(x_train):\n",
    "    model_close = Sequential()\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "\n",
    "    L1 = LSTM(16, activation='tanh', return_sequences=True, kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
    "    L2 = LSTM(4, activation='tanh', return_sequences=False)(L1)\n",
    "    L3 = RepeatVector(x_train.shape[1])(L2)\n",
    "    L4 = LSTM(4, activation='tanh', return_sequences=True)(L3)\n",
    "    L5 = LSTM(16, activation='tanh', return_sequences=True)(L4)\n",
    "\n",
    "    outputs = TimeDistributed(Dense(x_train.shape[2]))(L5)\n",
    "\n",
    "    model_close = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    model_close.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n",
    "    return model_close\n",
    "\n",
    "def architecture_one_head_11(x_train):\n",
    "\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(1*x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh',padding='same', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(Conv1D(2*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_2',padding='same'))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3',padding='same'))\n",
    "    modelC.add(Conv1D(4*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3',padding='same'))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3',padding='same'))\n",
    "    modelC.add(Conv1D(2*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3',padding='same'))\n",
    "    modelC.add(Conv1D(1*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3',padding='same'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce92c0",
   "metadata": {},
   "source": [
    "# Forecast in the sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef344891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_head(data, lags, batch_size, num_architecture):\n",
    "        scaler = preprocessing.MinMaxScaler() \n",
    "        frame= scaler.fit_transform(data)\n",
    "        x_train=split_sequence(frame,lags,1)[0]\n",
    "        y_train=split_sequence(frame,lags,1)[1]\n",
    "        \n",
    "        if num_architecture==0:\n",
    "            model=architecture_one_head_0(x_train)\n",
    "        if num_architecture==1:\n",
    "            model=architecture_one_head_1(x_train)\n",
    "        if num_architecture==2:\n",
    "            model=architecture_one_head_2(x_train)\n",
    "        if num_architecture==3:\n",
    "            model=architecture_one_head_3(x_train)\n",
    "        if num_architecture==4:\n",
    "            model=architecture_one_head_4(x_train)\n",
    "        if num_architecture==5:\n",
    "            model=architecture_one_head_5(x_train)\n",
    "        if num_architecture==6:\n",
    "            model=architecture_one_head_6(x_train)\n",
    "        if num_architecture==7:\n",
    "            model=architecture_one_head_7(x_train)\n",
    "        if num_architecture==8:\n",
    "            model=architecture_one_head_8(x_train)\n",
    "        if num_architecture==9:\n",
    "            model=architecture_one_head_9(x_train)\n",
    "        if num_architecture==10:\n",
    "            model=architecture_one_head_10(x_train)\n",
    "        if num_architecture==11:\n",
    "            model=architecture_one_head_11(x_train)\n",
    "\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "        model.fit(x_train,\n",
    "                  y_train, \n",
    "                    epochs=200, \n",
    "                                    batch_size=batch_size, #от размера батчей зависит точность модели, очень странная хуйня\n",
    "                                    verbose=0,\n",
    "                                    callbacks=[early_stop],\n",
    "                                    validation_split=0\n",
    "                                    )\n",
    "        return model\n",
    "\n",
    "def prog_sm_wind_one_head(frame, lags, batch_size, num_architecture):\n",
    "\n",
    "    iteratation_5=int((len(frame)-399)/5)+1\n",
    "#     iteratation_5=5\n",
    "    \n",
    "    prog=pd.DataFrame(columns=frame.columns)\n",
    "    orig=pd.DataFrame(columns=frame.columns)\n",
    "#     frr.loc[0]=testPredict\n",
    "    for i in range(0,iteratation_5):\n",
    "        modelC=one_head(frame.iloc[0+5*i:399+5*i,:], lags, batch_size, num_architecture)\n",
    "        scaler = preprocessing.MinMaxScaler() \n",
    "        frames=scaler.fit_transform(frame.iloc[0+5*i:399+1+5*i,:])\n",
    "        x_test=split_sequence(frames,lags,1)[0]\n",
    "        y_test=split_sequence(frames,lags,1)[1]\n",
    "        x_input = x_test[-1]\n",
    "        x_input = x_input.reshape((1, x_test.shape[1], x_test.shape[2]))\n",
    "        yhat = modelC.predict(x_input, verbose=0)\n",
    "        testPredict = scaler.inverse_transform(yhat[0])\n",
    "        testPredict=testPredict[0]\n",
    "        testY = scaler.inverse_transform(y_test[-1])\n",
    "        \n",
    "        prog.loc[i]=testPredict\n",
    "        orig.loc[i]=testY[0]\n",
    "    return orig, prog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7355651c",
   "metadata": {},
   "source": [
    "# Prediction repetition for result stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6236aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def povtor_prog_sqrt(frame, lags, batch_size, num_architecture, povtor):\n",
    "\n",
    "    prog_f1=pd.DataFrame()\n",
    "    for i in range(0,povtor):\n",
    "        prog=prog_sm_wind_one_head(frame, lags, batch_size, num_architecture)\n",
    "        prog_f1[str(i)]=prog[-1]\n",
    "    f1_mape=pd.DataFrame()\n",
    "    f1_mape['mean']=prog_f1.transpose().mean()\n",
    "    f1_mape['exp_prog']=np.exp(prog_f1).transpose().mean()\n",
    "    f1_mape['orig']=prog[-2]\n",
    "    f1_mape['orig_exp']=np.exp(prog[-2])\n",
    "    \n",
    "    c=np.exp(prog_f1).transpose().mean()\n",
    "    cc=f1_mape['orig_exp']\n",
    "    mape=100*(abs(c-cc)/cc).mean()\n",
    "    return f1_mape, mape, prog_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c26c12e",
   "metadata": {},
   "source": [
    "# Forecast for both values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00442e6",
   "metadata": {},
   "source": [
    "btc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2170bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# btc\n",
    "frame_3=pd.read_csv('all_snp_btc_rv_rr.csv', delimiter=';')\n",
    "frame=frame_3.iloc[:,1:3].copy() #на входе подаются квадраты волатильностей, поэтому сначала из них берем корни, а потом логарифмируем\n",
    "frame=frame.loc[:, [c for c in frame.columns if (frame[c]>0).all()]]\n",
    "frame=np.log(np.sqrt(frame))\n",
    "ind=[i for i in range(0,len(frame))]\n",
    "frame.index=ind\n",
    "\n",
    "prog1=povtor_prog_sqrt(frame, 5, 5,0,10)\n",
    "print(prog1[1])\n",
    "\n",
    "prog2=povtor_prog_sqrt(frame, 5, 5,1,10)\n",
    "print(prog2[1])\n",
    "\n",
    "prog3=povtor_prog_sqrt(frame,5, 5,2,10)\n",
    "print(prog3[1])\n",
    "\n",
    "prog4=povtor_prog_sqrt(frame, 5, 5,3,10)\n",
    "print(prog4[1])\n",
    "\n",
    "prog5=povtor_prog_sqrt(frame, 5, 5,4,10)\n",
    "print(prog5[1])\n",
    "\n",
    "prog6=povtor_prog_sqrt(frame, 5, 5,5,10)\n",
    "print(prog6[1])\n",
    "prog7=povtor_prog_sqrt(frame, 5, 5,6,10)\n",
    "print(prog7[1])\n",
    "prog8=povtor_prog_sqrt(frame, 5, 5,7,10)\n",
    "print(prog8[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccef843",
   "metadata": {},
   "source": [
    "snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba36dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# snp\n",
    "frame_3=pd.read_csv('all_snp_btc_rv_rr.csv', delimiter=';')\n",
    "frame=frame_3.iloc[:,2:].copy() #на входе подаются квадраты волатильностей, поэтому сначала из них берем корни, а потом логарифмируем\n",
    "frame=frame.loc[:, [c for c in frame.columns if (frame[c]>0).all()]]\n",
    "frame=np.log(np.sqrt(frame))\n",
    "ind=[i for i in range(0,len(frame))]\n",
    "frame.index=ind\n",
    "\n",
    "prog9=povtor_prog_sqrt(frame, 5, 5,0,10)\n",
    "print(prog9[1])\n",
    "\n",
    "prog10=povtor_prog_sqrt(frame, 5, 5,1,10)\n",
    "print(prog10[1])\n",
    "\n",
    "prog11=povtor_prog_sqrt(frame, 5, 5,2,10)\n",
    "print(prog11[1])\n",
    "\n",
    "prog12=povtor_prog_sqrt(frame, 5, 5,3,10)\n",
    "print(prog12[1])\n",
    "\n",
    "prog13=povtor_prog_sqrt(frame, 5, 5,4,10)\n",
    "print(prog13[1])\n",
    "\n",
    "prog14=povtor_prog_sqrt(frame, 5, 5,5,10)\n",
    "print(prog14[1])\n",
    "prog15=povtor_prog_sqrt(frame, 5, 5,6,10)\n",
    "print(prog15[1])\n",
    "prog16=povtor_prog_sqrt(frame, 5, 5,7,10)\n",
    "print(prog16[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1adcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(prog16[0]['exp_prog'], label='prog_lstm')\n",
    "\n",
    "\n",
    "plt.plot(prog11[0]['exp_prog'], label='prog_cnn')\n",
    "plt.plot(prog14[0]['exp_prog'], label='prog_mlp')\n",
    "plt.plot(prog16[0]['orig_exp'], label='orig')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009e4b59",
   "metadata": {},
   "source": [
    "# forecast retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_col=['rv','1_L_1_CNN','L_2_CNN','L_3_CNN','L_4_CNN','2_L_1_CNN', 'MLP', 'L_2_LSTM','L_1_LSTM']\n",
    "fr_btc=pd.DataFrame(columns=name_col)\n",
    "fr_btc['rv']=(vars()['prog'+str(1)])[0]['orig_exp']\n",
    "for s in range(1,9):\n",
    "    fr_btc[name_col[s]]=(vars()['prog'+str(s)])[0]['exp_prog']\n",
    "# print(fr_btc)\n",
    "fr_btc.to_csv('one_gate_forecast_btc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb69e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_snp=pd.DataFrame(columns=name_col)\n",
    "fr_snp['rv']=(vars()['prog'+str(1)])[0]['orig_exp']\n",
    "for s in range(9,17):\n",
    "#     print((vars()['prog'+str(s)])[0]['exp_prog'])\n",
    "    fr_snp[name_col[s-8]]=(vars()['prog'+str(s)])[0]['exp_prog']\n",
    "fr_snp.to_csv('one_gate_forecast_snp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
