{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d224e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from pandas import ExcelWriter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, RNN, GRU\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Bidirectional\n",
    "from keras.layers import Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from keras.layers import Flatten, Convolution1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation, GlobalAveragePooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, MaxPooling2D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import os\n",
    "os.chdir(\"C:/Users/VIP13/Статья 2/Котировки 6\")\n",
    "from numpy.random import seed\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa01632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, look_back, forecast_horizon):\n",
    " X, y = list(), list()\n",
    " for i in range(len(sequence)): \n",
    "   lag_end = i + look_back\n",
    "   forecast_end = lag_end + forecast_horizon\n",
    "   if forecast_end > len(sequence):\n",
    "     break\n",
    "   seq_x, seq_y = sequence[i:lag_end], sequence[lag_end:forecast_end]\n",
    "   X.append(seq_x)\n",
    "   y.append(seq_y)\n",
    " return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a243c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def architecture_one_head_0(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1]\n",
    "                      , activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])\n",
    "                     ,name='one_layer_CNN'))\n",
    "#     modelC.add(Conv1D(x_train.shape[2], kernel_size=1, activation='tanh'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='one_layer_CNN_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_1(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_2'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_2(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_2'))\n",
    "    modelC.add(Conv1D(2*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_3(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(4*x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(Conv1D(3*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_2'))\n",
    "    modelC.add(Conv1D(2*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_3'))\n",
    "    modelC.add(Conv1D(1*x_train.shape[1], kernel_size=1, activation='tanh'\n",
    "                     ,name='two_layer_CNN_4'))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_4(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(Conv1D(x_train.shape[2], x_train.shape[1],\n",
    "                      name='two_layer_CNN_1'\n",
    "                      ,activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layer_CNN_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_5(x_train): #СЮДА ВОТКНУТЬ снн-лстм\n",
    "   \n",
    "    modelC = Sequential()\n",
    "    modelC.add(Dense(64,activation='tanh',\n",
    "                     name='MLP_1',\n",
    "                     input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    for i in range(0,10):\n",
    "        modelC.add(Dense(32, name=str('MLP_'+str(i+2))))\n",
    "    modelC.add(Dense(x_train.shape[2], activation='tanh', name='MLP_output'))\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_6(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(LSTM(5*x_train.shape[1], return_sequences=True\n",
    "                    ,name='two_layer_LSTM_1'\n",
    "                    , activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    modelC.add(LSTM(10, activation='tanh'\n",
    "                    ,name='two_layer_LSTM_2'\n",
    "                    , return_sequences=True))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='two_layers_LSTM_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n",
    "def architecture_one_head_7(x_train):\n",
    "    modelC=Sequential()\n",
    "    modelC.add(LSTM(5*x_train.shape[1], return_sequences=True\n",
    "                    ,name='one_layer_LSTM_1'\n",
    "                    , activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "#     modelC.add(LSTM(25, activation='tanh', return_sequences=True))\n",
    "#     modelC.add(Flatten())\n",
    "    modelC.add(Dense(x_train.shape[2],name='one_layer_LSTM_model_output'))\n",
    "#     modelC.add(Dense(1, activation='tanh',name='CNN_model_output'))#здесь ставим столько, на сколько шагов хотим прогноз\n",
    "    early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "    modelC.compile(loss='mae', optimizer='adam')\n",
    "    return modelC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca50540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_head(data, lags, batch_size, num_architecture):\n",
    "        scaler = preprocessing.MinMaxScaler() \n",
    "        frame= scaler.fit_transform(data)\n",
    "        x_train=split_sequence(frame,lags,1)[0]\n",
    "        y_train=split_sequence(frame,lags,1)[1]\n",
    "        \n",
    "        if num_architecture==0:\n",
    "            model=architecture_one_head_0(x_train)\n",
    "        if num_architecture==1:\n",
    "            model=architecture_one_head_1(x_train)\n",
    "        if num_architecture==2:\n",
    "            model=architecture_one_head_2(x_train)\n",
    "        if num_architecture==3:\n",
    "            model=architecture_one_head_3(x_train)\n",
    "        if num_architecture==4:\n",
    "            model=architecture_one_head_4(x_train)\n",
    "        if num_architecture==5:\n",
    "            model=architecture_one_head_5(x_train)\n",
    "        if num_architecture==6:\n",
    "            model=architecture_one_head_6(x_train)\n",
    "        if num_architecture==7:\n",
    "            model=architecture_one_head_7(x_train)\n",
    "\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "        model.fit(x_train,\n",
    "                  y_train, \n",
    "                    epochs=200, \n",
    "                                    batch_size=batch_size, #от размера батчей зависит точность модел\n",
    "                                    verbose=0,\n",
    "                                    callbacks=[early_stop],\n",
    "                                    validation_split=0\n",
    "                                    )\n",
    "        return model\n",
    "\n",
    "def prog_sm_wind_one_head(frame, lags, batch_size, num_architecture):\n",
    "\n",
    "    iteratation_5=int((len(frame)-399)/5)+1\n",
    "#     iteratation_5=3\n",
    "\n",
    "    if num_architecture<8:\n",
    "        prog=pd.DataFrame(columns=frame.columns)\n",
    "        orig=pd.DataFrame(columns=frame.columns)\n",
    "    else:\n",
    "        prog=[]\n",
    "        orig=[]\n",
    "#     frr.loc[0]=testPredict\n",
    "    for i in range(0,iteratation_5):\n",
    "        modelC=one_head(frame.iloc[0+5*i:399+5*i,:], lags, batch_size, num_architecture)\n",
    "        scaler = preprocessing.MinMaxScaler() \n",
    "        frames=scaler.fit_transform(frame.iloc[0+5*i:399+1+5*i,:])\n",
    "        x_test=split_sequence(frames,lags,1)[0]\n",
    "        y_test=split_sequence(frames,lags,1)[1]\n",
    "        x_input = x_test[-1]\n",
    "        x_input = x_input.reshape((1, x_test.shape[1], x_test.shape[2]))\n",
    "        yhat = modelC.predict(x_input, verbose=0)\n",
    "        if num_architecture==8:\n",
    "            tmp=scaler.fit_transform(frame.iloc[0+5*i:399+1+5*i,0:1])\n",
    "            testPredict = scaler.inverse_transform(yhat[0])\n",
    "            testPredict=testPredict[0]\n",
    "            testY = scaler.inverse_transform(y_test[-1])\n",
    "\n",
    "            prog.append(testPredict)\n",
    "            orig.append(testY[0])\n",
    "        else:\n",
    "            testPredict = scaler.inverse_transform(yhat[0])\n",
    "            testPredict=testPredict[0]\n",
    "            testY = scaler.inverse_transform(y_test[-1])\n",
    "\n",
    "            prog.loc[i]=testPredict\n",
    "            orig.loc[i]=testY[0]\n",
    "    return orig, prog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f51cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def povtor_prog_sqrt(frame, lags, batch_size, num_architecture, povtor):\n",
    "\n",
    "    if len(frame.columns)==1 or num_architecture==8:\n",
    "        names_frames='only_one_frame'\n",
    "        prog_iter=pd.DataFrame()\n",
    "        for i in range(0,povtor):\n",
    "                prog=prog_sm_wind_one_head(frame, lags, batch_size, num_architecture)\n",
    "                prog_iter[str(i)]=prog[-1]\n",
    "        df_exp_prog=np.exp(prog_iter).transpose().mean()\n",
    "        orig_data=np.exp(prog[0])\n",
    "        f1_mape=pd.DataFrame()\n",
    "        f1_mape['exp_prog']=df_exp_prog\n",
    "        f1_mape['orig_exp']=orig_data\n",
    "        c=f1_mape['exp_prog']\n",
    "        cc=f1_mape['orig_exp']\n",
    "        mape_all=100*(abs(c-cc)/cc).mean()\n",
    "                \n",
    "\n",
    "    else:\n",
    "        for s in range(0,len(frame.columns)):\n",
    "            (vars()['df'+ '_'+str(s)])=pd.DataFrame()\n",
    "\n",
    "        for i in range(0,povtor):\n",
    "            prog=prog_sm_wind_one_head(frame, lags, batch_size, num_architecture)\n",
    "            for s in range(0,len(frame.columns)):\n",
    "                (vars()['df'+ '_'+str(s)])[str(i)]=prog[-1].iloc[:,s]\n",
    "\n",
    "        names_frames=[]\n",
    "        for s in range(0,len(frame.columns)):\n",
    "                names_frames.append(vars()['df'+ '_'+str(s)])\n",
    "\n",
    "        df_exp_prog=[]\n",
    "        mape_all=[]\n",
    "        orig_data=[]\n",
    "        for s in range(0,len(frame.columns)):\n",
    "            (vars()['df'+'_'+'exp'+ '_'+str(s)])=np.exp((vars()['df'+ '_'+str(s)])).transpose().mean()\n",
    "            (vars()['orig_data'+'_'+str(s)])=np.exp(prog[0].iloc[:,s])\n",
    "        for s in range(0,len(frame.columns)):\n",
    "            c=(vars()['df'+'_'+'exp'+ '_'+str(s)])\n",
    "            cc=(vars()['orig_data'+'_'+str(s)])\n",
    "            ccc=100*(abs(cc-c)/cc).mean()\n",
    "\n",
    "            df_exp_prog.append(c)\n",
    "            mape_all.append(ccc)\n",
    "            orig_data.append(cc)\n",
    "    return mape_all, df_exp_prog, orig_data, names_frames\n",
    "# print(mape_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e04022",
   "metadata": {},
   "outputs": [],
   "source": [
    "Прогон для БИТКА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b95472",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_3=pd.read_csv('all_snp_btc_rv_rr.csv', delimiter=';')\n",
    "frame=frame_3.iloc[:,1:3].copy() #на входе подаются квадраты волатильностей, поэтому сначала из них берем корни, а потом логарифмируем\n",
    "frame=frame.loc[:, [c for c in frame.columns if (frame[c]>0).all()]]\n",
    "frame=np.log(np.sqrt(frame))\n",
    "ind=[i for i in range(0,len(frame))]\n",
    "frame.index=ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac7308",
   "metadata": {},
   "outputs": [],
   "source": [
    "prog1=povtor_prog_sqrt(frame, 5, 5,0,10)\n",
    "print(prog1[0])\n",
    "\n",
    "prog2=povtor_prog_sqrt(frame, 5, 5,1,10)\n",
    "print(prog2[0])\n",
    "\n",
    "prog3=povtor_prog_sqrt(frame, 5, 5,2,10)\n",
    "print(prog3[0])\n",
    "\n",
    "prog4=povtor_prog_sqrt(frame, 5, 5,3,10)\n",
    "print(prog4[0])\n",
    "\n",
    "prog5=povtor_prog_sqrt(frame, 5, 5,4,10)\n",
    "print(prog5[0])\n",
    "\n",
    "prog6=povtor_prog_sqrt(frame, 5, 5,5,10)\n",
    "print(prog6[0])\n",
    "prog7=povtor_prog_sqrt(frame, 5, 5,6,10)\n",
    "print(prog7[0])\n",
    "prog8=povtor_prog_sqrt(frame, 5, 5,7,10)\n",
    "print(prog8[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "Прогон для СНП"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d2eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_3=pd.read_csv('all_snp_btc_rv_rr.csv', delimiter=';')\n",
    "frame=frame_3.iloc[:,2:].copy() #на входе подаются квадраты волатильностей, поэтому сначала из них берем корни, а потом логарифмируем\n",
    "frame=frame.loc[:, [c for c in frame.columns if (frame[c]>0).all()]]\n",
    "frame=np.log(np.sqrt(frame))\n",
    "ind=[i for i in range(0,len(frame))]\n",
    "frame.index=ind\n",
    "# print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14be76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prog9=povtor_prog_sqrt(frame, 5, 5,0,10)\n",
    "print(prog9[0])\n",
    "\n",
    "prog10=povtor_prog_sqrt(frame, 5, 5,1,10)\n",
    "print(prog10[0])\n",
    "\n",
    "prog11=povtor_prog_sqrt(frame, 5, 5,2,10)\n",
    "print(prog11[0])\n",
    "\n",
    "prog12=povtor_prog_sqrt(frame, 5, 5,3,10)\n",
    "print(prog12[0])\n",
    "\n",
    "prog13=povtor_prog_sqrt(frame, 5, 5,4,10)\n",
    "print(prog13[0])\n",
    "\n",
    "prog14=povtor_prog_sqrt(frame, 5, 5,5,10)\n",
    "print(prog14[0])\n",
    "prog15=povtor_prog_sqrt(frame, 5, 5,6,10)\n",
    "print(prog15[0])\n",
    "prog16=povtor_prog_sqrt(frame, 5, 5,7,10)\n",
    "print(prog16[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13070409",
   "metadata": {},
   "outputs": [],
   "source": [
    "Прогон с ДВУМЯ ПРИЗНАКАМИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11756e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_3=pd.read_csv('all_snp_btc_rv_rr.csv', delimiter=';')\n",
    "frame=frame_3.iloc[:,1:].copy() #на входе подаются квадраты волатильностей, поэтому сначала из них берем корни, а потом логарифмируем\n",
    "frame=frame.loc[:, [c for c in frame.columns if (frame[c]>0).all()]]\n",
    "frame=np.log(np.sqrt(frame))\n",
    "ind=[i for i in range(0,len(frame))]\n",
    "frame.index=ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87734d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FF5ADA4B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FF526BA700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[25.8411579146453, 35.52205773887639]\n",
      "[26.00383789256625, 35.60507943253564]\n",
      "[26.318689573577885, 36.18913447764733]\n",
      "[26.278742646964936, 35.82122396387602]\n",
      "[26.208865506992314, 35.362105172577984]\n",
      "[33.910455312389345, 45.33496441996652]\n",
      "[33.79712098947586, 44.321972082470914]\n",
      "[33.46502463619593, 45.081746898058356]\n"
     ]
    }
   ],
   "source": [
    "prog17=povtor_prog_sqrt(frame, 5, 5,0,10)\n",
    "print(prog17[0])\n",
    "\n",
    "prog18=povtor_prog_sqrt(frame, 5, 5,1,10)\n",
    "print(prog18[0])\n",
    "\n",
    "prog19=povtor_prog_sqrt(frame, 5, 5,2,10)\n",
    "print(prog19[0])\n",
    "\n",
    "prog20=povtor_prog_sqrt(frame, 5, 5,3,10)\n",
    "print(prog20[0])\n",
    "\n",
    "prog21=povtor_prog_sqrt(frame, 5, 5,4,10)\n",
    "print(prog21[0])\n",
    "\n",
    "prog22=povtor_prog_sqrt(frame, 5, 5,5,10)\n",
    "print(prog22[0])\n",
    "prog23=povtor_prog_sqrt(frame, 5, 5,6,10)\n",
    "print(prog23[0])\n",
    "prog24=povtor_prog_sqrt(frame, 5, 5,7,10)\n",
    "print(prog24[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc63180f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           rv  1_L_1_CNN   L_2_CNN   L_3_CNN   L_4_CNN  2_L_1_CNN       MLP  \\\n",
      "0    0.023228   0.033439  0.033198  0.032812  0.032854   0.034227  0.031148   \n",
      "1    0.017602   0.019663  0.019803  0.020160  0.019506   0.020591  0.024424   \n",
      "2    0.054841   0.026136  0.026100  0.024320  0.025638   0.026204  0.020974   \n",
      "3    0.016580   0.021715  0.022690  0.021167  0.022253   0.021578  0.041992   \n",
      "4    0.037197   0.024233  0.025540  0.025401  0.025070   0.025695  0.017221   \n",
      "..        ...        ...       ...       ...       ...        ...       ...   \n",
      "165  0.042247   0.033730  0.033910  0.033974  0.032671   0.032966  0.029143   \n",
      "166  0.048504   0.035906  0.037340  0.035742  0.037528   0.037324  0.038035   \n",
      "167  0.028435   0.039893  0.039719  0.041285  0.040216   0.039229  0.040854   \n",
      "168  0.021812   0.029021  0.027849  0.030485  0.029516   0.029044  0.030125   \n",
      "169  0.032482   0.027301  0.027991  0.027687  0.028683   0.027713  0.026990   \n",
      "\n",
      "     L_2_LSTM  L_1_LSTM  \n",
      "0    0.028530  0.028818  \n",
      "1    0.022589  0.023872  \n",
      "2    0.019360  0.019981  \n",
      "3    0.037614  0.037242  \n",
      "4    0.019061  0.019639  \n",
      "..        ...       ...  \n",
      "165  0.030737  0.031117  \n",
      "166  0.037972  0.037938  \n",
      "167  0.040690  0.039574  \n",
      "168  0.031078  0.031861  \n",
      "169  0.029350  0.028806  \n",
      "\n",
      "[170 rows x 9 columns]\n",
      "           rv  1_L_1_CNN   L_2_CNN   L_3_CNN   L_4_CNN  2_L_1_CNN       MLP  \\\n",
      "0    0.005634   0.004983  0.005122  0.005055  0.004883   0.005062  0.004651   \n",
      "1    0.005747   0.004743  0.004625  0.004571  0.004536   0.004796  0.006413   \n",
      "2    0.006069   0.004612  0.004673  0.004644  0.004684   0.004725  0.006614   \n",
      "3    0.006507   0.005020  0.004946  0.005105  0.005107   0.004983  0.007225   \n",
      "4    0.011949   0.009327  0.009450  0.009674  0.009981   0.009278  0.006795   \n",
      "..        ...        ...       ...       ...       ...        ...       ...   \n",
      "165  0.008220   0.013744  0.013182  0.013253  0.013153   0.013592  0.008286   \n",
      "166  0.009446   0.007271  0.007327  0.007223  0.007617   0.007444  0.007363   \n",
      "167  0.011195   0.009018  0.008658  0.009475  0.009284   0.008896  0.007951   \n",
      "168  0.006320   0.009778  0.009709  0.010355  0.009884   0.009875  0.008669   \n",
      "169  0.005017   0.006584  0.006458  0.006765  0.006928   0.006632  0.007248   \n",
      "\n",
      "     L_2_LSTM  L_1_LSTM  \n",
      "0    0.004826  0.004964  \n",
      "1    0.006090  0.006286  \n",
      "2    0.006193  0.006180  \n",
      "3    0.006667  0.006701  \n",
      "4    0.006375  0.006503  \n",
      "..        ...       ...  \n",
      "165  0.008054  0.007894  \n",
      "166  0.007309  0.007346  \n",
      "167  0.007558  0.007679  \n",
      "168  0.008869  0.008571  \n",
      "169  0.006861  0.006760  \n",
      "\n",
      "[170 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(prog24[1][0])#0-btc, 1-snp\n",
    "# print(prog24[1][1])\n",
    "\n",
    "# print(prog24[2][0])\n",
    "# print(prog24[2][1])\n",
    "\n",
    "name_col=['rv','1_L_1_CNN','L_2_CNN','L_3_CNN','L_4_CNN','2_L_1_CNN', 'MLP', 'L_2_LSTM','L_1_LSTM']\n",
    "fr_btc=pd.DataFrame(columns=name_col)\n",
    "fr_btc['rv']=(vars()['prog'+str(17)])[2][0]\n",
    "\n",
    "fr_snp=pd.DataFrame(columns=name_col)\n",
    "fr_snp['rv']=(vars()['prog'+str(17)])[2][1]\n",
    "for s in range(17,25):\n",
    "    fr_btc[name_col[s-16]]=(vars()['prog'+str(s)])[1][0]\n",
    "    fr_snp[name_col[s-16]]=(vars()['prog'+str(s)])[1][1]\n",
    "print(fr_btc)\n",
    "print(fr_snp)\n",
    "fr_btc.to_csv('fr_btc_2.csv')\n",
    "fr_snp.to_csv('fr_snp_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
